# Добро пожаловать на первый этап твоей стажировки!

И вот инструкции на предстоящую неделю ↓

Первый спринт нашего проекта посвящён оценке ориентации человека в графическом формате (Human Pose Skeleton).

По сути, это набор координат, которые можно связать для описания позы человека (освежить тему в памяти можно тут). Каждая координата в скелете — это ключевая точка (key point). Правильное соединение между двумя частями называется ветвью (limb).

img
Итак, в качестве первого шага к созданию виртуального коуча тебе необходимо определить ключевые точки спортсмена на фото и на их основе построить каркас позы человека, а именно осуществить следующую цепочку преобразований изображения бегущей девушки.

Нажмите на изображение, чтобы открыть его в полном размере ↓


Как это сделать? Сейчас будем разбираться!




# Спринт I: построение каркаса позы через ключевые точки
Для создания Human Pose Skeleton можно воспользоваться архитектурой Keypoint RCNN, имплементация которой представлена в библиотеке torchvision.

Модель обучена на наборе данных MS-COCO (Common Objects in Context) с целью обнаружения 17 ключевых точек человеческого тела (нос, глаза, уши, плечи, локти, запястья, бёдра, колени и лодыжки).

Архитектура Keypoint RCNN представлена на рисунке ниже.

img
Источник изображения
img
Модель выводит список из следующих элементов:

- boxes — тензор размера [N, 4], где N — количество обнаруженных объектов.
- labels — тензор размера [N], класс объекта. Он всегда равен 1, так как каждый обнаруженный «ящик» указывает на человека. 0 обозначает фоновый класс.
- scores — тензор размера [N], отображающий показатель достоверности обнаруженного объекта.
- keypoints — тензор размера [N, 17, 3], отображающий 17 ключевых точек N человек. Первые два числа — координаты x и y, а третье — видимость.
- keypoints_scores — тензор размера [N, 17], отражающий оценку всех ключевых точек для каждого обнаруженного человека.

Keypoint RCNN имеет готовую реализацию в обёртке PyTorch. С помощью данной модели мы без труда детектируем ключевые точки человеческого тела (от глаз до лодыжек) на изображении, а также получаем степень достоверности этих обнаружений.

Нам предстоит воспользоваться уже обученной сетью для отрисовки каркаса бегущей девушки.

Аутсорсный CV-инженер успел частично подготовить для нас перечень шагов, необходимых для отрисовки каркаса человека.

Наша задача — воспроизвести готовые и дописать пропущенные части кода.

1. Загрузи предобученную сеть torchvision.models.detection.keypointrcnn_resnet50_fpn и подготовь её для инференса.

2. Создай список опорных точек:

```python
keypoints = ['nose','left_eye','right_eye',\
'left_ear','right_ear','left_shoulder',\
'right_shoulder','left_elbow','right_elbow',\
'left_wrist','right_wrist','left_hip',\
'right_hip','left_knee', 'right_knee', \
'left_ankle','right_ankle']
```
3. Загрузи и примени трансформации transforms.Compose([T.ToTensor()]) к изображению бегущей девушки.

<img src='https://lms-cdn.skillfactory.ru/assets/courseware/v1/916f2b30ed417a727ebf512c413d20dd/asset-v1:SkillFactory+DSPR-CV+ALWAYS+type@asset+block/dspr_cv_u1_diploma_spr1_3_1.png'>

4. Прогони изображение через модель для получения ключевых точек.

5. Отрисуй ключевые точки с помощью функции draw_keypoints_per_person:

```python
def draw_keypoints_per_person(img, all_keypoints, all_scores, confs,           keypoint_threshold=2, conf_threshold=0.9):
    # создаём спектр цветов
    cmap = plt.get_cmap("rainbow")
    # создаём копию изображений
    img_copy = img.copy()
    color_id = np.arange(1, 255, 255 // len(all_keypoints)).tolist()[::-1]
    # для каждого задетектированного человека
    for person_id in range(len(all_keypoints)):
        # проверяем степень уверенности детектора
        if confs[person_id] > conf_threshold:
            # собираем ключевые точки конкретного человека
            keypoints = all_keypoints[person_id, ...]
            # собираем скоры для ключевых точек
            scores = all_scores[person_id, ...]
            # итерируем по каждому скору
            for kp in range(len(scores)):
                # проверяем степень уверенности детектора опорной точки
                if scores[kp] > keypoint_threshold:
                    # конвертируем массив ключевых точек в список целых чисел
                    keypoint = tuple(
                        map(int, keypoints[kp, :2].detach().numpy().tolist())
                    )
                    # выбираем цвет
                    color = tuple(np.asarray(cmap(color_id[person_id])[:-1]) * 255)
                    # рисуем кружок радиуса 5 вокруг точки
                    cv2.circle(img_copy, keypoint, 5, color, -1)

    return img_copy
```
6. Используя вспомогательную функцию, создай список «конечностей» девушки:

```python
def get_limbs_from_keypoints(keypoints):
    limbs = [
        [keypoints.index("right_eye"), keypoints.index("nose")],
        [keypoints.index("right_eye"), keypoints.index("right_ear")],
        [keypoints.index("left_eye"), keypoints.index("nose")],
        [keypoints.index("left_eye"), keypoints.index("left_ear")],
        [keypoints.index("right_shoulder"), keypoints.index("right_elbow")],
        [keypoints.index("right_elbow"), keypoints.index("right_wrist")],
        [keypoints.index("left_shoulder"), keypoints.index("left_elbow")],
        [keypoints.index("left_elbow"), keypoints.index("left_wrist")],
        [keypoints.index("right_hip"), keypoints.index("right_knee")],
        [keypoints.index("right_knee"), keypoints.index("right_ankle")],
        [keypoints.index("left_hip"), keypoints.index("left_knee")],
        [keypoints.index("left_knee"), keypoints.index("left_ankle")],
        [keypoints.index("right_shoulder"), keypoints.index("left_shoulder")],
        [keypoints.index("right_hip"), keypoints.index("left_hip")],
        [keypoints.index("right_shoulder"), keypoints.index("right_hip")],
        [keypoints.index("left_shoulder"), keypoints.index("left_hip")],
    ]
    return limbs


limbs = get_limbs_from_keypoints(keypoints)
```

7. Создай функцию для отрисовки каркаса (скелета) на базе уже имеющейся функции отрисовки ключевых точек.

8. Отрисуй каркас на изображении.

9. Сохрани получившийся ноутбук — он пригодится тебе в следующих спринтах.




Отлично! У тебя всё получилось, и теперь ты умеешь определять каркас человека по фото.

Для того чтобы создать виртуального коуча, также надо научиться сравнивать полученную позу с референсной.

О том, какие метрики помогут справиться с этой задачей и как это поможет нашему коучу, тимлид расскажет тебе в следующем спринте!

Предыдущий спринт помог тебе разобраться, как отрисовывать скелет человека по опорным точкам. Из исходного изображения бегущей спортсменки ты получил подобную картинку:


Для этого ты самостоятельно написал функцию отрисовки скелета. Давай сверим её с нашим вариантом draw_skeleton_per_person().


Функция draw_skeleton_per_person() принимает на вход изображение img, ключевые точки all_keypoints, оценку всех ключевых точек для каждого обнаруженного человека all_scores, показатель достоверности обнаруженных объектов confs, а также пороги keypoint_threshold и conf_threshold.

```python
def draw_skeleton_per_person(img, all_keypoints, all_scores, confs, keypoint_threshold=2, conf_threshold=0.9):
# Для каждого найденного человека:
# проверяем степень уверенности детектора confs[person_id]
if confs[person_id] > conf_threshold:
	# собираем опорные точки конкретного человека
	# для каждой ветви (пары опорных точек):
				# выбираем первоначальную точку конечности 1 и 2
				# считаем limb_score как минимальную оценку ключевой точки среди двух оценок ключевых точек
				# проверяем, превосходит ли скор конечностей порог
				if limb_score> keypoint_threshold:
					# рисуем линию
```

Полный вариант решения ты найдёшь в [ноутбуке](https://lms-cdn.skillfactory.ru/assets/courseware/v1/4b85b34b3158f55b869215a855d1c8c0/asset-v1:SkillFactory+DSPR-CV+ALWAYS+type@asset+block/skeletal_img_creation.ipynb). 

Для получения каркаса человека также можно использовать другие подходы, например [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose).


# Сравнение поз

Первый этап на пути к созданию виртуального коуча пройден! Теперь, когда ты умеешь оценивать каркас человека по фото, перейдём к сравнению поз двух людей, выполняющих заданное упражнение, на двух изображениях.

Давай сравним две позы. Идея в том, что коуч задаёт человеку модельную позу, которую он должен попытаться повторить. После фотографирования решается, соответствует ли входная поза позе коуча.


Итак, у нас есть два набора ключевых точек:

- Модельный набор (который нужно имитировать).
- Ввод (необходимо сопоставить его с модельным набором).
Как же сравнить эти два набора?

Задача сводится к тому, чтобы проверить формы поз на одинаковость. Для её решения можно использовать [наложение Прокруста](https://wikipedia.day/wiki/Procrustes_analysis), которое выполняется путём оптимального перемещения, вращения и равномерного масштабирования объектов. Другими словами, свободно регулируется как размещение в пространстве, так и размер объектов. Цель состоит в том, чтобы получить аналогичное размещение и размер, минимизируя меру различия формы, называемую прокрустовым расстоянием между объектами.

<img src="https://lms-cdn.skillfactory.ru/assets/courseware/v1/003c6c35f6dd3ee933ffed72731afe7e/asset-v1:SkillFactory+DSPR-CV+ALWAYS+type@asset+block/dspr_cv_u1_diploma_spr2_2_1.png">

Итак, нам необходима комбинация переноса, масштабирования и поворота, которая лучше всего преобразует исходную позу в позу модели. В линейной алгебре такая комбинация представлена аффинным преобразованием.


Свойства аффинного преобразования:

- линии сопоставляются с линиями;
- параллельные линии остаются параллельными;
- исходный вектор не обязательно отображается в исходный;
- соотношения сохраняются.


После того как преобразование входного изображения применено, мы можем использовать метрики расстояния для оценки сходства выполненных действий на фотографиях.


# Метрики расстояния

Аффинное отображение (преобразование) $f()$ входного вектора $x$ в модельный вектор $y$ выглядит следующим образом:

$$y =f(x) = Ax + b$$

С помощью расширенной матрицы можно умножить вектор $x$ на матрицу $A$ и добавить вектор $b$ за счёт единственного матричного умножения.

Эта расширенная матрица создаётся следующим образом:

- Дополняем все векторы «1» в конце.
- Дополняем матрицу строкой нулей внизу.
- Дополняем матрицу столбцом (вектором переноса) справа и «1» в правом нижнем углу.

```python
# Соберём два набора ключевых точек
model_key_points = [[x1,y2],[x2,y2],...]
input_key_points = [[x1,y2],[x2,y2],...]
 
# С помощью расширенной матрицы можно осуществить умножение вектора x на матрицу A и добавление вектора b за счёт единственного матричного умножения.
# Расширенная матрица создаётся путём дополнения векторов "1" в конце.
pad = lambda x: np.hstack([x, np.ones((x.shape[0], 1))])
unpad = lambda x: x[:, :-1]
 
# Расширим наборы ключевых точек до [[ x y 1] , [x y 1]]
Y = pad(model_key_points)
X = pad(input_key_points)
```
В нашем случае X (входная поза) и y (поза модели) известны и мы хотим найти расширенную матрицу. Используя алгоритм наименьших квадратов (который минимизирует сумму квадратов), мы можем аппроксимировать решение этой линейной системы и найти матрицу аффинного преобразования.
```python
# Решим задачу наименьших квадратов X * A = Y
# и найдём матрицу аффинного преобразования A.
A, res, rank, s = np.linalg.lstsq(X, Y)
A[np.abs(A) < 1e-10] = 0  # превратим в "0" слишком маленькие значения

# Теперь, когда мы нашли расширенную матрицу A,
# мы можем преобразовать входной набор ключевых точек
transform = lambda x: unpad(np.dot(pad(x), A))
input_transform = transform(input_key_points)
```
Итак, при сравнении поз на двух картинках стоит учитывать, что изображения могут иметь разный размер, человек может появиться в разных местах фотографии и т. д. С помощью аффинного отображения мы получили преобразованный набор ключевых точек, необходимый для корректного сравнения позы спортсмена с модельной. Пришло время перейти к оценке «сходства» двух поз.


# Косинусное сходство и взвешенное совпадение

Теперь, когда у нас есть преобразованный вход X, мы можем сравнить его с позой модели. Для определения «сходства» X и y можно воспользоваться косинусным сходством и взвешенным совпадением с учётом показателей достоверности ключевых точек.

**Косинусное сходство** — это мера сходства между двумя векторами: в основном оно измеряет угол между ними и возвращает -1, если они прямо противоположны, и 1, если они абсолютно одинаковы. Важно отметить, что это мера ориентации, а не величины.

<img src="https://lms-cdn.skillfactory.ru/assets/courseware/v1/5c5757869d376243cdd86d2797c078ba/asset-v1:SkillFactory+DSPR-CV+ALWAYS+type@asset+block/dspr_cv_u1_diploma_spr2_4_1.png">


Взвешенное совпадение позволяет учесть степень достоверности ключевой точки: соединения с низкой достоверностью должны оказывать меньшее влияние на показатель совпадения, чем соединения с высокой степенью достоверности.

```python
def cosine_distance(pose1, pose2):
    cossin = pose1.dot(np.transpose(pose2)) / (
        np.linalg.norm(pose1) * np.linalg.norm(pose2)
    )
    dist = cossim

    return dist


def weight_distance(pose1, pose2, conf1):
    # D(U,V) = (1 / sum(conf1)) * sum(conf1 * ||pose1 - pose2||) = sum1 * sum2

    sum1 = 1 / np.sum(conf1)
    sum2 = 0

    for i in range(len(pose1)):
        # каждый индекс i имеет x и y, у которых одинаковая оценка достоверности
        conf_ind = math.floor(i / 2)
        sum2 = conf1[conf_ind] * abs(pose1[i] - pose2[i])

    weighted_dist = sum1 * sum2

    return weighted_dist

```
**Подведём итог.** 
>Благодаря алгоритмам сходства, таким как косинусное сходство и взвешенное совпадение, мы можем анализировать близость между двумя оценками позы человека. Сходство косинуса рассчитывается путём создания векторов поз и оценки косинуса угла между ними. Взвешенное совпадение учитывают оценку достоверности каждой отдельно найденной ключевой точки так, чтобы более реалистичные ключевые точки в большей степени влияли на результат.



Теперь, когда ты знаешь, как сравнивать две позы по двум фотографиям, попробуй повторить движение нашей бегущей спортсменки.

img Попроси сфотографировать тебя (или сфотографируй друга/ найди другого бегущего спортсмена в интернете), а затем оцени сходство поз на заданном и твоём изображениях.

Какие значения косинусного сходства и взвешенного совпадения у тебя получились?

Сохрани свою работу — она пригодится тебе в дальнейших спринтах.

img
img
Отличный результат! Однако нам бы хотелось сравнивать не просто фотографии, а видео! В следующем спринте тебе предстоит работа с видеороликом.

До встречи!